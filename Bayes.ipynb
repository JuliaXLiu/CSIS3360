{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ded9ccd-a029-4bfc-85ec-6441afed07c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# set all the input here\n",
    "input_file = \"bayes - basic.xlsx\"\n",
    "input_cols = 'A:E'\n",
    "target_col = 'Enrolls'\n",
    "predict_row = [\"<=30\",\"Medium\",\"Yes\",\"Fair\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1af0266d-c995-4172-8c4b-acabd745f38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'No': 5, 'Yes': 9}\n",
      "{'Age': ['<=30', '31 to 40', '>40'], 'Income': ['High', 'Medium', 'Low'], 'JobSatisfaction': ['No', 'Yes'], 'Desire': ['Fair', 'Excellent']}\n"
     ]
    }
   ],
   "source": [
    "# Read all training data from excel\n",
    "df = pd.read_excel(input_file, usecols=input_cols)\n",
    "# Remove the row with null target column\n",
    "df[target_col] = df[target_col].str.strip().replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "# Define feature list\n",
    "features = [feature for feature in list(df.columns) if feature != target_col]\n",
    "\n",
    "train_sample = df.dropna(subset=[target_col])\n",
    "test_sample = []\n",
    "if (predict_row is None or predict_row == 0):\n",
    "    pass\n",
    "else:\n",
    "    test_sample = pd.Series([item.strip() for item in predict_row], index=features)\n",
    "\n",
    "classes = train_sample[target_col].unique().tolist()\n",
    "\n",
    "# calculate the distribution of target column\n",
    "total_samples = len(df)\n",
    "class_probs = {\n",
    "    cls: df[df[target_col] == cls].shape[0]\n",
    "    for cls in classes\n",
    "}\n",
    "\n",
    "feature_probs = {}\n",
    "feature_config = {feature: df[feature].dropna().unique().tolist() for feature in features}\n",
    "\n",
    "print(class_probs)\n",
    "print(feature_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1d5f03f-d47c-4599-8229-830125be96f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: Age\n",
      "          No  Yes  No_prob  Yes_prob\n",
      "Age                                 \n",
      "<=30       4    2    0.500    0.2222\n",
      "31 to 40   1    4    0.125    0.4444\n",
      ">40        3    3    0.375    0.3333\n",
      "\n",
      "\n",
      "Feature: Income\n",
      "        No  Yes  No_prob  Yes_prob\n",
      "Income                            \n",
      "High     2    2      0.4    0.2222\n",
      "Medium   2    4      0.4    0.4444\n",
      "Low      1    3      0.2    0.3333\n",
      "\n",
      "\n",
      "Feature: JobSatisfaction\n",
      "                 No  Yes  No_prob  Yes_prob\n",
      "JobSatisfaction                            \n",
      "No                4    3      0.8    0.3333\n",
      "Yes               1    6      0.2    0.6667\n",
      "\n",
      "\n",
      "Feature: Desire\n",
      "           No  Yes  No_prob  Yes_prob\n",
      "Desire                               \n",
      "Fair        2    6      0.4    0.6667\n",
      "Excellent   3    3      0.6    0.3333\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check if apply laplace smoothing\n",
    "# add 1 if there is 0 in the feature column\n",
    "def apply_smoothing(counts, total, k):\n",
    "    if (counts == 0).any():\n",
    "        return counts + 1, total + k\n",
    "    return counts, total\n",
    "\n",
    "# Calculate the probability for each feature\n",
    "for feature, possible_values in feature_config.items():\n",
    "    k = len(possible_values)  # The number of possible values ​​a feature can take\n",
    "\n",
    "    count_table = {}\n",
    "    prob_table = {}\n",
    "    feature_values = {}\n",
    "    \n",
    "    feature_values[feature] = df[feature].dropna().unique().tolist()\n",
    "    for cls in classes:\n",
    "        cls_data = df[df[target_col] == cls]\n",
    "        counts = cls_data[feature].value_counts()\n",
    "        counts = counts.reindex(feature_values[feature], fill_value=0)\n",
    "        counts_smoothed, denominator = apply_smoothing(counts, class_probs[cls], k)\n",
    "        count_table[cls] = counts_smoothed\n",
    "        prob_table[cls] = (counts_smoothed / denominator).round(4)\n",
    "\n",
    "    result_count = pd.DataFrame(count_table)\n",
    "    result_prob = pd.DataFrame(prob_table)\n",
    "    result_prob.columns = [col+\"_prob\" for col in result_prob.columns]\n",
    "    feature_probs[feature] = result_prob\n",
    "    print(f\"Feature: {feature}\")\n",
    "    print(pd.concat([result_count,result_prob],axis=1))\n",
    "    print(\"\\n\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "098e5f4d-c859-4201-90b8-2cd11e71f434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value feature \n",
      "Age                  <=30\n",
      "Income             Medium\n",
      "JobSatisfaction       Yes\n",
      "Desire               Fair\n",
      "\n",
      "Predicted result probability：\n",
      "No: 0.57%\n",
      "Yes: 2.82%\n",
      "\n",
      "Final Predicton: Yes\n"
     ]
    }
   ],
   "source": [
    "def predict(sample):\n",
    "    prob_dic = {cls: class_probs[cls]/sum(class_probs.values()) for cls in classes}\n",
    "    for feature in features:\n",
    "        value = sample[feature]\n",
    "        feature_df = feature_probs[feature]\n",
    "        # Get probabilities\n",
    "        for cls in classes:\n",
    "            prob_dic[cls] *= feature_df[cls+\"_prob\"][value]\n",
    "            \n",
    "    return prob_dic\n",
    "\n",
    "# Prediction\n",
    "prediction = predict(test_sample)\n",
    "\n",
    "# ----------------- Outcome -----------------\n",
    "print(\"Predicted value feature \")\n",
    "print(test_sample.to_string())\n",
    "print(\"\\nPredicted result probability：\")\n",
    "for cls, prob in prediction.items():\n",
    "    print(f\"{cls}: {prob:.2%}\")\n",
    "print(f\"\\nFinal Predicton: {max(prediction, key=prediction.get)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1412b5d-218c-442f-a3aa-2a32aa94d3fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
